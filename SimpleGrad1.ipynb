{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP62oRxW+fe30nBejFsg5OK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everestso/Summer24/blob/main/SimpleGrad1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Gradient Descent Example"
      ],
      "metadata": {
        "id": "S_ZZ4byOJLDJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W_Gd4ARLJH4Y"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create a simple gradients descent example using as input integers from range(10) using the equation y= 2 + 3x\n",
        "\n",
        "# Define the function\n",
        "def f(x, w):\n",
        "  return w[0] + w[1] * x\n",
        "\n",
        "w_orig = (2.0,3.0)\n",
        "# Initialize the weights\n",
        "w_test=(0.0,0.0)\n",
        "w = torch.tensor(w_test, requires_grad=True)\n",
        "x_list = list(range(10))\n",
        "y_list = [f(x, w_orig) for x in x_list]\n",
        "pred_list = [f(x, w_test) for x in x_list]\n",
        "# Define the input data\n",
        "print (f\"{x_list=}\")\n",
        "print (f\"{y_list=}\")\n",
        "print (f\"{pred_list=}\")\n",
        "learning_rate=0.03\n",
        "for _ in range(25):\n",
        "  print (f\"{sum([(y-f(x, w_test))**2 for x,y in zip(x_list,y_list)])}\")\n",
        "  for i in range(10):\n",
        "    item = i\n",
        "    w = torch.tensor(w_test, requires_grad=True)\n",
        "    x = torch.tensor(x_list[item], dtype=torch.float32, requires_grad=True)\n",
        "    y = torch.tensor(y_list[item], dtype=torch.float32, requires_grad=True)\n",
        "    loss = (y - f(x, w))**2\n",
        "    loss.backward()\n",
        "    #print (f\"{w.grad=}\")\n",
        "    w_test = (w[0]-learning_rate* w.grad[0], w[1]-learning_rate*w.grad[1])\n",
        "    #print (f\"{w_test=}\")\n",
        "    w.grad.zero_()\n",
        "\n",
        "print (f\"{w_test[0]:.2f}, {w_test[1]:.2f}, {w_orig=}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJByb4TDJPEX",
        "outputId": "acf245c6-0cb3-49bc-8efd-ba1249e1015f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "y_list=[2.0, 5.0, 8.0, 11.0, 14.0, 17.0, 20.0, 23.0, 26.0, 29.0]\n",
            "pred_list=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "3145.0\n",
            "50.54237365722656\n",
            "5.835329532623291\n",
            "2.800790548324585\n",
            "1.782610535621643\n",
            "1.1742467880249023\n",
            "0.7762038707733154\n",
            "0.5126916170120239\n",
            "0.3387297987937927\n",
            "0.22406457364559174\n",
            "0.14800329506397247\n",
            "0.09783980995416641\n",
            "0.06470861285924911\n",
            "0.042806029319763184\n",
            "0.02836495265364647\n",
            "0.01872478984296322\n",
            "0.012342322617769241\n",
            "0.008188323117792606\n",
            "0.005445810034871101\n",
            "0.003540023695677519\n",
            "0.0023562167771160603\n",
            "0.001561347278766334\n",
            "0.0010232658823952079\n",
            "0.0006766583537682891\n",
            "0.00044678631820715964\n",
            "2.00, 3.00, w_orig=(2.0, 3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create a simple gradients descent example using as input integers from range(10) using the equation y= 2 + 3x\n",
        "\n",
        "# Define the function\n",
        "def f(x, w):\n",
        "  return w[0] + w[1] * x\n",
        "\n",
        "w_orig = (3.0,5.0)\n",
        "# Initialize the weights\n",
        "w_test=(0.0,0.0)\n",
        "w = torch.tensor(w_test, requires_grad=True)\n",
        "x_list = list(range(10))\n",
        "y_list = [f(x, w_orig) for x in x_list]\n",
        "pred_list = [f(x, w_test) for x in x_list]\n",
        "# Define the input data\n",
        "print (f\"{x_list=}\")\n",
        "print (f\"{y_list=}\")\n",
        "print (f\"{pred_list=}\")\n",
        "learning_rate=0.03\n",
        "for _ in range(25):\n",
        "  print (f\"{sum([(y-f(x, w_test))**2 for x,y in zip(x_list,y_list)])}\")\n",
        "  for i in range(10):\n",
        "    item = i\n",
        "    w = torch.tensor(w_test, requires_grad=True)\n",
        "    x = torch.tensor(x_list[item], dtype=torch.float32, requires_grad=True)\n",
        "    y = torch.tensor(y_list[item], dtype=torch.float32, requires_grad=True)\n",
        "    loss = (y - f(x, w))**2\n",
        "    loss.backward()\n",
        "    #print (f\"{w.grad=}\")\n",
        "    w_test = (w[0]-learning_rate* w.grad[0], w[1]-learning_rate*w.grad[1])\n",
        "    #print (f\"{w_test=}\")\n",
        "    w.grad.zero_()\n",
        "\n",
        "print (f\"{w_test[0]:.2f}, {w_test[1]:.2f}, {w_orig=}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbYj32BRJdZe",
        "outputId": "e50c4a78-497a-4724-acd4-17b11eb5a25b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "y_list=[3.0, 8.0, 13.0, 18.0, 23.0, 28.0, 33.0, 38.0, 43.0, 48.0]\n",
            "pred_list=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "8565.0\n",
            "110.43677520751953\n",
            "8.197516441345215\n",
            "3.3766303062438965\n",
            "2.1074559688568115\n",
            "1.382805585861206\n",
            "0.9141682386398315\n",
            "0.6043360829353333\n",
            "0.39986687898635864\n",
            "0.2641352713108063\n",
            "0.17430467903614044\n",
            "0.11568157374858856\n",
            "0.07649444043636322\n",
            "0.05029994621872902\n",
            "0.03319070115685463\n",
            "0.021896418184041977\n",
            "0.014549586921930313\n",
            "0.009655408561229706\n",
            "0.006342933513224125\n",
            "0.004267261829227209\n",
            "0.0028012897819280624\n",
            "0.0018546557985246181\n",
            "0.0012117711594328284\n",
            "0.0008367495029233396\n",
            "0.0005450514145195484\n",
            "3.00, 5.00, w_orig=(3.0, 5.0)\n"
          ]
        }
      ]
    }
  ]
}